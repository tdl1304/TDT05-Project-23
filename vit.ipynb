{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (23.3.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: urllib3<2 in ./venv/lib/python3.10/site-packages (1.26.18)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install datasets accelerate transformers tqdm torch torchvision torchaudio requests \"urllib3<2\" scikit-learn matplotlib\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "from transformers import TrainingArguments\n",
    "from transformers import ViTForImageClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.ones(1).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   1%|          | 470/60000 [00:00<00:12, 4652.10 examples/s]/home/tommydl/TDT05-Project-23/venv/lib/python3.10/site-packages/datasets/features/image.py:332: UserWarning: Downcasting array dtype int64 to uint8 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n",
      "Map: 100%|██████████| 60000/60000 [07:26<00:00, 134.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    d_types = ['train'] # 60k images\n",
    "    datasets = []\n",
    "    for d in d_types:\n",
    "        datasets.append(load_dataset(\n",
    "            'mnist',\n",
    "            split=d,\n",
    "        ))\n",
    "    return datasets\n",
    "\n",
    "# 94% for validation, 1% for test and 5% for training\n",
    "dataset = load_data()[0].map(lambda x: {'image': torch.tensor(np.repeat(np.array(x['image'])[:, :, np.newaxis], 3, axis=2)), 'label': x['label']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 3000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 600\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 56400\n",
       " }))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = dataset.train_test_split(test_size=0.94)\n",
    "temp_split = split['train'].train_test_split(test_size=1/6)\n",
    "dataset_train = temp_split['train']\n",
    "dataset_test = temp_split['test']\n",
    "dataset_valid = split['test']\n",
    "dataset_train, dataset_test, dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many labels/number of classes\n",
    "num_classes = len(set(dataset_train['label']))\n",
    "labels = dataset_train.features['label'].names\n",
    "num_classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['image'][1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85806346"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import feature extraction model\n",
    "model_id = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_id,  # classification head\n",
    "    num_labels=len(labels)\n",
    ").to(device)\n",
    "\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    # take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor(\n",
    "        batch['image'],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    # include the labels\n",
    "    inputs['labels'] = batch['label']\n",
    "    return inputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "# transform the training dataset\n",
    "prepared_train = dataset_train.with_transform(preprocess)\n",
    "# ... and the testing dataset\n",
    "prepared_test = dataset_test.with_transform(preprocess)\n",
    "# ... and the validation dataset\n",
    "prepared_valid = dataset_valid.with_transform(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "# accuracy metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions=np.argmax(p.predictions, axis=1),\n",
    "        references=p.label_ids\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/470 [00:03<02:21,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0823, 'learning_rate': 0.00019574468085106384, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 20/470 [00:06<02:22,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3311, 'learning_rate': 0.00019148936170212768, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 30/470 [00:10<02:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7644, 'learning_rate': 0.0001872340425531915, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 40/470 [00:12<02:01,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.493, 'learning_rate': 0.00018297872340425532, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 50/470 [00:15<02:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3984, 'learning_rate': 0.00017872340425531915, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 60/470 [00:18<01:54,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3148, 'learning_rate': 0.00017446808510638298, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 70/470 [00:21<01:55,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2579, 'learning_rate': 0.00017021276595744682, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 80/470 [00:24<01:53,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1984, 'learning_rate': 0.00016595744680851065, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 90/470 [00:27<01:50,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1677, 'learning_rate': 0.00016170212765957446, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 100/470 [00:30<01:46,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1566, 'learning_rate': 0.00015744680851063832, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██▏       | 100/470 [00:33<01:46,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17012116312980652, 'eval_accuracy': 0.9766666666666667, 'eval_runtime': 3.3638, 'eval_samples_per_second': 178.371, 'eval_steps_per_second': 22.296, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 110/470 [00:38<02:20,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1605, 'learning_rate': 0.00015319148936170213, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 120/470 [00:41<01:55,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1046, 'learning_rate': 0.00014893617021276596, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 130/470 [00:45<01:47,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1483, 'learning_rate': 0.0001446808510638298, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 140/470 [00:48<01:44,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1723, 'learning_rate': 0.00014042553191489363, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 150/470 [00:51<01:34,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1265, 'learning_rate': 0.00013617021276595746, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 160/470 [00:54<01:30,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0971, 'learning_rate': 0.00013191489361702127, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 170/470 [00:57<01:27,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1056, 'learning_rate': 0.00012765957446808513, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 180/470 [01:00<01:23,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1073, 'learning_rate': 0.00012340425531914893, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 190/470 [01:03<01:22,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1069, 'learning_rate': 0.00011914893617021277, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 200/470 [01:05<01:18,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0738, 'learning_rate': 0.00011489361702127661, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 200/470 [01:09<01:18,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14511671662330627, 'eval_accuracy': 0.9683333333333334, 'eval_runtime': 3.2586, 'eval_samples_per_second': 184.126, 'eval_steps_per_second': 23.016, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 210/470 [01:13<01:36,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0508, 'learning_rate': 0.00011063829787234043, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 220/470 [01:16<01:14,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.074, 'learning_rate': 0.00010638297872340425, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 230/470 [01:19<01:14,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0572, 'learning_rate': 0.00010212765957446809, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 240/470 [01:22<01:07,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0614, 'learning_rate': 9.787234042553192e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 250/470 [01:25<01:06,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0641, 'learning_rate': 9.361702127659576e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 260/470 [01:27<01:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0477, 'learning_rate': 8.936170212765958e-05, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 270/470 [01:30<00:58,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0543, 'learning_rate': 8.510638297872341e-05, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 280/470 [01:33<00:55,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0437, 'learning_rate': 8.085106382978723e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 290/470 [01:36<00:52,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0551, 'learning_rate': 7.659574468085106e-05, 'epoch': 3.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 300/470 [01:39<00:49,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0286, 'learning_rate': 7.23404255319149e-05, 'epoch': 3.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 300/470 [01:43<00:49,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07216043025255203, 'eval_accuracy': 0.9883333333333333, 'eval_runtime': 3.7862, 'eval_samples_per_second': 158.47, 'eval_steps_per_second': 19.809, 'epoch': 3.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 310/470 [01:47<00:56,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0267, 'learning_rate': 6.808510638297873e-05, 'epoch': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 320/470 [01:50<00:44,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0294, 'learning_rate': 6.382978723404256e-05, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 330/470 [01:53<00:43,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0241, 'learning_rate': 5.9574468085106384e-05, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 340/470 [01:56<00:38,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0241, 'learning_rate': 5.531914893617022e-05, 'epoch': 3.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 350/470 [01:59<00:35,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0277, 'learning_rate': 5.1063829787234044e-05, 'epoch': 3.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 360/470 [02:02<00:31,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0224, 'learning_rate': 4.680851063829788e-05, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 370/470 [02:05<00:29,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.028, 'learning_rate': 4.2553191489361704e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 380/470 [02:08<00:26,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0213, 'learning_rate': 3.829787234042553e-05, 'epoch': 4.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 390/470 [02:11<00:23,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0209, 'learning_rate': 3.4042553191489365e-05, 'epoch': 4.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 400/470 [02:14<00:22,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0204, 'learning_rate': 2.9787234042553192e-05, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 400/470 [02:18<00:22,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.069559246301651, 'eval_accuracy': 0.9883333333333333, 'eval_runtime': 3.9994, 'eval_samples_per_second': 150.022, 'eval_steps_per_second': 18.753, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 410/470 [02:22<00:20,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0202, 'learning_rate': 2.5531914893617022e-05, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 420/470 [02:25<00:14,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0212, 'learning_rate': 2.1276595744680852e-05, 'epoch': 4.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 430/470 [02:28<00:11,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0199, 'learning_rate': 1.7021276595744682e-05, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 440/470 [02:31<00:08,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0198, 'learning_rate': 1.2765957446808511e-05, 'epoch': 4.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 450/470 [02:33<00:05,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0191, 'learning_rate': 8.510638297872341e-06, 'epoch': 4.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 460/470 [02:36<00:02,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0195, 'learning_rate': 4.255319148936171e-06, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 470/470 [02:39<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0348, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 159.7352, 'train_samples_per_second': 93.905, 'train_steps_per_second': 2.942, 'train_loss': 0.17668168240405144, 'epoch': 5.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     0.1767\n",
      "  train_runtime            = 0:02:39.73\n",
      "  train_samples_per_second =     93.905\n",
      "  train_steps_per_second   =      2.942\n"
     ]
    }
   ],
   "source": [
    "eval_save_step = 100\n",
    "\n",
    "# training the model\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./vit_model\",\n",
    "  per_device_train_batch_size=32,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=5,\n",
    "  save_steps=eval_save_step,\n",
    "  eval_steps=eval_save_step,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  optim='adamw_torch',\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_test,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "train_results = trainer.train(resume_from_checkpoint=False)\n",
    "# save tokenizer with the model\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "# save the trainer state\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7050/7050 [05:26<00:00, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =     0.9899\n",
      "  eval_loss               =     0.0544\n",
      "  eval_runtime            = 0:05:27.07\n",
      "  eval_samples_per_second =    172.435\n",
      "  eval_steps_per_second   =     21.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate with validation\n",
    "metrics = trainer.evaluate(prepared_valid)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ViT: Loss over train steps')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = [log['step'] for log in trainer.state.log_history if 'loss' in log]\n",
    "y = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
    "\n",
    "\n",
    "# y axis is loss\n",
    "# x axis is step\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('ViT: Loss over train steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommydl/TDT05-Project-23/venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85806346"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine tuned model\n",
    "# import our fine-tuned model\n",
    "model_name_or_path = './vit_model'\n",
    "model_finetuned = ViTForImageClassification.from_pretrained(model_name_or_path)\n",
    "# import features\n",
    "feature_extractor_finetuned = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "model_finetuned.num_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    inputs = feature_extractor_finetuned(image[\"image\"], return_tensors=\"pt\")\n",
    "    # extract the actual label of the first image of the testing dataset\n",
    "    actual_label = image[\"label\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_finetuned(**inputs).logits\n",
    "\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 0\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/rrPAPgmfxprTQvKbXS7VPOv71uEhjHPU8AnBxn0J6A1yscbyyLGilnYhVA6kmvXfHt8PAfgHTPh9YtGL65jF3rMiDkljlUPXngZ9kXs1AHE+O/DNl4b1qEaRczXejXsCXNjdS4zIhHPQDkHIPAPtXLV6TrunNa/Ajw1PdQ7LiTUpmgLj5jCynp7EqD+RrzagDR0C8h07xHpl7cDMFvdxSyDBPyq4J6ewr2rWdM+Gs3ii+8aa94vg1aG5k86HTLTG44AAVwCWPAHB2+/FeCUUAdh8QvHlx461iKb7OLTTrRPKs7VTxGvGSccZOB06YA7Vx9FFAH/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB80lEQVR4Ae1Vv6tBYRjmIkkGTAwGg1KKrP4AZVEWJp3FYlEoCyVFVlmsSpJBbGwWWUWsLAwoGWQQ7nPvV6ev813nnnO6d/MOX+95nvd9zvvDd6hUb5M2Ab1e3+12H49Ho9EwmUzSkkSjDAZDu92+3+8QxRkOh0XCP0Q4morFYtFoFMj1esWJd9CsEt9ut59OJxQI83g8x+NxuVzabDYlWiQHimgZhhr9fj/AdDqNx2KxqFAUC1mtVpBAjRzHERWdTtdsNheLhdlslq2L5FqtBjmIrtdrut9sNgu8UqnIFvV6vciEQdTn89H5RHQ4HNIg72t5j3VQmlqtBl6tVmezmSAAFGEFuNijy+U6HA4oE7tm40ilk8kEI2LZl7/TUChksVjQeLlcZtPcbjcBn88ny/6MOJ3O7XaLMne7HRuBpW82G7DyZhoIBMiuk8kkK1qv1x0OB/DpdMqyL5F+v4/G5/O5VivcZKlUut1uZNbyLiv6gmir1aJfq9FoCoUCcCjCcrkczf7iY2T7/R7JmUyGDwXY6/WgRUQ7nY7VauVZSc5oNMJaI5EIonH3cc0vlwvkiGGUSi4oaf98PmP7+D5B67vjryOfzxuNRkmlCYISiQQtRPzxeBwMBgWR8h7j8fhgMCAF4puUSqX+5i9EXhXv6H+dwCct3Sdmqqt/fQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0, len(dataset_valid)-1)\n",
    "print(\"Predicted \"+str(predict(dataset_valid[index])))\n",
    "dataset_valid[index][\"image\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

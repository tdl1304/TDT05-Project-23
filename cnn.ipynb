{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (23.3.1)\n",
      "Requirement already satisfied: datasets in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: torch in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: torchvision in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: requests in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (2.30.0)\n",
      "Requirement already satisfied: urllib3<2 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (1.26.15)\n",
      "Requirement already satisfied: scikit-learn in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: packaging in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tommyluu/Documents/projects/vit/venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install datasets torch transformers torchvision torchaudio requests \"urllib3<2\" scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification, TrainingArguments, Trainer, ResNetConfig, ResNetForImageClassification\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.ones(1).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset chest-xray-classification (/Users/tommyluu/.cache/huggingface/datasets/trpakov___chest-xray-classification/full/1.0.0/395971eacf4f6d99e8b95f965fa0a8af5a31a5118529992bba3f60c4a7af1b92)\n",
      "Found cached dataset chest-xray-classification (/Users/tommyluu/.cache/huggingface/datasets/trpakov___chest-xray-classification/full/1.0.0/395971eacf4f6d99e8b95f965fa0a8af5a31a5118529992bba3f60c4a7af1b92)\n",
      "Found cached dataset chest-xray-classification (/Users/tommyluu/.cache/huggingface/datasets/trpakov___chest-xray-classification/full/1.0.0/395971eacf4f6d99e8b95f965fa0a8af5a31a5118529992bba3f60c4a7af1b92)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image_file_path', 'image', 'labels'],\n",
       "    num_rows: 12230\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    d_types = ['train','test','validation']\n",
    "    datasets = []\n",
    "    for d in d_types:\n",
    "        datasets.append(load_dataset(\n",
    "            'trpakov/chest-xray-classification',\n",
    "            'full',\n",
    "            split=d,\n",
    "        ))\n",
    "    return datasets\n",
    "\n",
    "dataset_train, dataset_test, dataset_valid = load_data()\n",
    "dataset_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, ['PNEUMONIA', 'NORMAL'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many labels/number of classes\n",
    "num_classes = len(set(dataset_train['labels']))\n",
    "labels = dataset_train.features['labels'].names\n",
    "num_classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature extraction model\n",
    "model_id = 'microsoft/resnet-50'\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "config = ResNetConfig()\n",
    "config.num_labels = num_classes\n",
    "model = ResNetForImageClassification(config)\n",
    "model = model.from_pretrained(\n",
    "    model_id,  # classification head\n",
    ").train().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    # take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor(\n",
    "        batch['image'],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    # include the labels\n",
    "    inputs['labels'] = batch['labels']\n",
    "    return inputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "# transform the training dataset\n",
    "prepared_train = dataset_train.with_transform(preprocess)\n",
    "# ... and the testing dataset\n",
    "prepared_test = dataset_test.with_transform(preprocess)\n",
    "# ... and the validation dataset\n",
    "prepared_valid = dataset_valid.with_transform(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "# accuracy metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions=np.argmax(p.predictions, axis=1),\n",
    "        references=p.label_ids\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/766 [02:42<?, ?it/s]\n",
      "  1%|▏         | 10/766 [01:07<1:21:48,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.715, 'learning_rate': 0.0009869451697127939, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/766 [02:12<1:20:14,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5802, 'learning_rate': 0.0009738903394255875, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 30/766 [03:16<1:18:20,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2781, 'learning_rate': 0.0009608355091383812, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 40/766 [04:19<1:16:51,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2414, 'learning_rate': 0.0009477806788511749, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 50/766 [05:24<1:18:05,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1592, 'learning_rate': 0.0009347258485639687, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 60/766 [06:28<1:14:35,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1929, 'learning_rate': 0.0009216710182767625, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 70/766 [07:32<1:14:19,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1253, 'learning_rate': 0.0009086161879895561, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 80/766 [08:36<1:12:31,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.219, 'learning_rate': 0.00089556135770235, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 90/766 [09:39<1:11:42,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1913, 'learning_rate': 0.0008825065274151436, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 100/766 [10:45<1:11:52,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1239, 'learning_rate': 0.0008694516971279373, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 13%|█▎        | 100/766 [11:03<1:11:52,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20632897317409515, 'eval_accuracy': 0.9243986254295533, 'eval_runtime': 17.3052, 'eval_samples_per_second': 33.631, 'eval_steps_per_second': 4.218, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 110/766 [12:10<1:16:15,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1571, 'learning_rate': 0.0008563968668407311, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 120/766 [13:16<1:10:12,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2204, 'learning_rate': 0.0008433420365535248, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 130/766 [14:24<1:11:36,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1548, 'learning_rate': 0.0008302872062663186, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 133/766 [14:44<1:10:27,  6.68s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "output_dir = './resnet_model'\n",
    "\n",
    "# training the model\n",
    "training_args = TrainingArguments(\n",
    "  output_dir,\n",
    "  per_device_train_batch_size=32,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=2,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=0.001,\n",
    "  save_total_limit=2,\n",
    "  optim='adamw_torch',\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_test,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "#change resume_from_checkpoint to True if you want to resume training\n",
    "train_results = trainer.train(resume_from_checkpoint=False)\n",
    "# save tokenizer with the model\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "# save the trainer state\n",
    "trainer.save_state()\n",
    "# evaluate with validation\n",
    "metrics = trainer.evaluate(prepared_valid)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = [log['step'] for log in trainer.state.log_history if 'loss' in log]\n",
    "y = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
    "\n",
    "\n",
    "# y axis is loss\n",
    "# x axis is step\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('ResNet50: Loss over train steps')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

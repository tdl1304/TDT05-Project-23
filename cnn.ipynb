{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: pip in ./venv/lib/python3.10/site-packages (23.3.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.14.6)\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: urllib3<2 in ./venv/lib/python3.10/site-packages (1.26.18)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in ./venv/lib/python3.10/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.idi.ntnu.no\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install datasets accelerate transformers tqdm torch torchvision torchaudio requests \"urllib3<2\" scikit-learn matplotlib\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoFeatureExtractor, ResNetForImageClassification, ResNetConfig, Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.ones(1).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    d_types = ['train'] # 60k images\n",
    "    datasets = []\n",
    "    for d in d_types:\n",
    "        datasets.append(load_dataset(\n",
    "            'mnist',\n",
    "            split=d,\n",
    "        ))\n",
    "    return datasets\n",
    "\n",
    "# 94% for validation, 1% for test and 5% for training\n",
    "dataset = load_data()[0].map(lambda x: {'image': torch.tensor(np.repeat(np.array(x['image'])[:, :, np.newaxis], 3, axis=2)), 'label': x['label']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 3000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 600\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['image', 'label'],\n",
       "     num_rows: 56400\n",
       " }))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = dataset.train_test_split(test_size=0.94)\n",
    "temp_split = split['train'].train_test_split(test_size=1/6)\n",
    "dataset_train = temp_split['train']\n",
    "dataset_test = temp_split['test']\n",
    "dataset_valid = split['test']\n",
    "dataset_train, dataset_test, dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many labels/number of classes\n",
    "num_classes = len(set(dataset_train['label']))\n",
    "labels = dataset_train.features['label'].names\n",
    "num_classes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['image'][1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import feature extraction model\n",
    "model_id = 'microsoft/resnet-50'\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id\n",
    ")\n",
    "config = ResNetConfig()\n",
    "config.num_labels = num_classes\n",
    "model = ResNetForImageClassification(config)\n",
    "model = model.from_pretrained(\n",
    "    model_id,  # classification head\n",
    ").train().to(device)\n",
    "\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    # take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor(\n",
    "        batch['image'],\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    # include the labels\n",
    "    inputs['labels'] = batch['label']\n",
    "    return inputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "# transform the training dataset\n",
    "prepared_train = dataset_train.with_transform(preprocess)\n",
    "# ... and the testing dataset\n",
    "prepared_test = dataset_test.with_transform(preprocess)\n",
    "# ... and the validation dataset\n",
    "prepared_valid = dataset_valid.with_transform(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13226/1389652664.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "# accuracy metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(\n",
    "        predictions=np.argmax(p.predictions, axis=1),\n",
    "        references=p.label_ids\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 10/470 [00:07<02:15,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.2699, 'learning_rate': 0.00019574468085106384, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 20/470 [00:10<01:56,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.715, 'learning_rate': 0.00019148936170212768, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 30/470 [00:12<01:43,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2164, 'learning_rate': 0.0001872340425531915, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–Š         | 41/470 [00:14<01:25,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7825, 'learning_rate': 0.00018297872340425532, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 51/470 [00:16<01:22,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.784, 'learning_rate': 0.00017872340425531915, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 60/470 [00:18<01:27,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1513, 'learning_rate': 0.00017446808510638298, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–        | 70/470 [00:21<01:53,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0236, 'learning_rate': 0.00017021276595744682, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 80/470 [00:23<01:31,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.711, 'learning_rate': 0.00016595744680851065, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 90/470 [00:25<01:32,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6479, 'learning_rate': 0.00016170212765957446, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆâ–       | 100/470 [00:28<01:32,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4359, 'learning_rate': 0.00015744680851063832, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 21%|â–ˆâ–ˆâ–       | 100/470 [00:32<01:32,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.738985300064087, 'eval_accuracy': 0.3416666666666667, 'eval_runtime': 4.1253, 'eval_samples_per_second': 145.443, 'eval_steps_per_second': 18.18, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 110/470 [00:34<01:34,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3832, 'learning_rate': 0.00015319148936170213, 'epoch': 1.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–Œ       | 121/470 [00:37<01:09,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3572, 'learning_rate': 0.00014893617021276596, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 131/470 [00:39<01:07,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2998, 'learning_rate': 0.0001446808510638298, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 141/470 [00:41<01:07,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2934, 'learning_rate': 0.00014042553191489363, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 151/470 [00:43<01:03,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2933, 'learning_rate': 0.00013617021276595746, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 161/470 [00:45<01:01,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.241, 'learning_rate': 0.00013191489361702127, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 171/470 [00:47<01:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1706, 'learning_rate': 0.00012765957446808513, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 181/470 [00:49<00:57,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2158, 'learning_rate': 0.00012340425531914893, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 191/470 [00:51<00:53,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1201, 'learning_rate': 0.00011914893617021277, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 200/470 [00:52<00:53,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.137, 'learning_rate': 0.00011489361702127661, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 200/470 [00:56<00:53,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4768838584423065, 'eval_accuracy': 0.86, 'eval_runtime': 3.7275, 'eval_samples_per_second': 160.968, 'eval_steps_per_second': 20.121, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 210/470 [00:59<01:13,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1048, 'learning_rate': 0.00011063829787234043, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 220/470 [01:01<01:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0981, 'learning_rate': 0.00010638297872340425, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 230/470 [01:04<00:58,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1152, 'learning_rate': 0.00010212765957446809, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/470 [01:06<00:55,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1176, 'learning_rate': 9.787234042553192e-05, 'epoch': 2.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 250/470 [01:09<00:54,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0379, 'learning_rate': 9.361702127659576e-05, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 260/470 [01:11<00:50,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0605, 'learning_rate': 8.936170212765958e-05, 'epoch': 2.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 270/470 [01:14<00:50,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1042, 'learning_rate': 8.510638297872341e-05, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 281/470 [01:16<00:42,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0964, 'learning_rate': 8.085106382978723e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 290/470 [01:18<00:42,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0572, 'learning_rate': 7.659574468085106e-05, 'epoch': 3.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 300/470 [01:21<00:40,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0354, 'learning_rate': 7.23404255319149e-05, 'epoch': 3.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 300/470 [01:24<00:40,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1034337729215622, 'eval_accuracy': 0.965, 'eval_runtime': 3.6721, 'eval_samples_per_second': 163.393, 'eval_steps_per_second': 20.424, 'epoch': 3.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 310/470 [01:27<00:46,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0387, 'learning_rate': 6.808510638297873e-05, 'epoch': 3.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 320/470 [01:29<00:36,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0618, 'learning_rate': 6.382978723404256e-05, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 330/470 [01:32<00:28,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0464, 'learning_rate': 5.9574468085106384e-05, 'epoch': 3.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 340/470 [01:34<00:31,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0588, 'learning_rate': 5.531914893617022e-05, 'epoch': 3.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 350/470 [01:36<00:28,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0337, 'learning_rate': 5.1063829787234044e-05, 'epoch': 3.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 360/470 [01:39<00:25,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053, 'learning_rate': 4.680851063829788e-05, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 371/470 [01:41<00:19,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0408, 'learning_rate': 4.2553191489361704e-05, 'epoch': 3.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 381/470 [01:43<00:17,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0391, 'learning_rate': 3.829787234042553e-05, 'epoch': 4.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 390/470 [01:45<00:16,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0189, 'learning_rate': 3.4042553191489365e-05, 'epoch': 4.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 400/470 [01:47<00:13,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0429, 'learning_rate': 2.9787234042553192e-05, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 400/470 [01:50<00:13,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07702630013227463, 'eval_accuracy': 0.9766666666666667, 'eval_runtime': 3.4989, 'eval_samples_per_second': 171.483, 'eval_steps_per_second': 21.435, 'epoch': 4.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 410/470 [01:53<00:17,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0152, 'learning_rate': 2.5531914893617022e-05, 'epoch': 4.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 420/470 [01:56<00:12,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0207, 'learning_rate': 2.1276595744680852e-05, 'epoch': 4.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 430/470 [01:58<00:09,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0303, 'learning_rate': 1.7021276595744682e-05, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 440/470 [02:00<00:06,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.008, 'learning_rate': 1.2765957446808511e-05, 'epoch': 4.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 450/470 [02:03<00:04,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0139, 'learning_rate': 8.510638297872341e-06, 'epoch': 4.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 460/470 [02:05<00:02,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0197, 'learning_rate': 4.255319148936171e-06, 'epoch': 4.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 470/470 [02:07<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0118, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 127.7213, 'train_samples_per_second': 117.443, 'train_steps_per_second': 3.68, 'train_loss': 0.6304153577761448, 'epoch': 5.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        5.0\n",
      "  train_loss               =     0.6304\n",
      "  train_runtime            = 0:02:07.72\n",
      "  train_samples_per_second =    117.443\n",
      "  train_steps_per_second   =       3.68\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "eval_save_step = 100\n",
    "\n",
    "# training the model\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./cnn_model\",\n",
    "  per_device_train_batch_size=32,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=5,\n",
    "  save_steps=eval_save_step,\n",
    "  eval_steps=eval_save_step,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  optim='adamw_torch',\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_train,\n",
    "    eval_dataset=prepared_test,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n",
    "\n",
    "train_results = trainer.train(resume_from_checkpoint=False)\n",
    "# save tokenizer with the model\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "# save the trainer state\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7050/7050 [05:23<00:00, 21.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        5.0\n",
      "  eval_accuracy           =     0.9671\n",
      "  eval_loss               =     0.1082\n",
      "  eval_runtime            = 0:05:24.08\n",
      "  eval_samples_per_second =     174.03\n",
      "  eval_steps_per_second   =     21.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate with valid\n",
    "metrics = trainer.evaluate(prepared_valid)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ResNet: Loss over train steps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = [log['step'] for log in trainer.state.log_history if 'loss' in log]\n",
    "y = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
    "\n",
    "\n",
    "# y axis is loss\n",
    "# x axis is step\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('ResNet: Loss over train steps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommydl/TDT05-Project-23/venv/lib/python3.10/site-packages/transformers/models/convnext/feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# fine tuned model\n",
    "# import our fine-tuned model\n",
    "model_name_or_path = './cnn_model'\n",
    "model_finetuned = ResNetForImageClassification.from_pretrained(model_name_or_path)\n",
    "# import features\n",
    "feature_extractor_finetuned = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    inputs = feature_extractor_finetuned(image[\"image\"], return_tensors=\"pt\")\n",
    "    # extract the actual label of the first image of the testing dataset\n",
    "    actual_label = image[\"label\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model_finetuned(**inputs).logits\n",
    "\n",
    "    predicted_label = logits.argmax(-1).item()\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 1\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ro/CngnWPGn9oJoywyTWUImaF32tICcYTjGfqRXOV7R+zda7/GWrXe/Hlaf5e3HXdIhzn22frQB41NFJBNJDKpSSNirKeoIOCKZXQeO/wDkofiX/sK3X/o1q5+gAr2f9nu5ayv/ABPdKoZoNOEgU9CVJOP0rxirFtf3lkk6Wt3PAtxGYplikKiRD1VsdR7GgBdRvp9U1O71C5INxdTPPKR0LMSx/U1WoooA/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAkElEQVR4Ae2UQQ4AEQxFmZO5GTdTJzM/kVi0ou1uRlgIVS//lzSEO86pQCml947ZaOkx5iEt51xrTSmpVxxQsEDEUKFRzRgJsD8zY1Ru+ZRO7n5xGNT+mUZZDrO/f2t5+g37RCSlsYhbaWuNIeTWB4VMy/fyQS0yIdwHlU6Xkf9Al/J5EI0Z/RRtnx/c/aoCL5jrIRuSGX3TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0, len(dataset_valid))\n",
    "print(\"Predicted \"+str(predict(dataset_valid[index])))\n",
    "dataset_valid[index][\"image\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
